# 반직관적 발견: 왜 T=0.8에서 쉬운 문제가 T=0.1에서 어려울 수 있는가?

## 직관적 기대 vs 실제

### 직관 (논리적으로 보임) 🤔
```
T=0.8에서 L1 (80-100% 정확도)
  → 노이즈가 많은데도 잘 풀림
  → T=0.1 (더 집중적)에서는 당연히 더 잘 풀릴 것
  → T=0.1에서도 L1이어야 함
```

### 실제 데이터 (BoN) 📊
```
ref0.8 L1: 198개 문제
ref0.1 L1: 225개 문제

차이: 27개 문제가 어디로 갔나?
```

**일부 문제가 ref0.8에서 L1이지만 ref0.1에서는 L2나 L3입니다!**

## 왜 이런 일이 발생하는가? 🔍

### 핵심: 난이도는 "단일 시도"가 아닌 "다중 샘플 평균"으로 측정됨

**측정 방법:**
```python
# 난이도 측정 (is_correct_preds 사용)
baseline_accuracy = (
    모든 completions의 정확도 평균
    across N개 샘플 × 3개 시드
)
```

**중요한 차이점:**
- N=64 샘플링 후 평균 정확도 측정
- 단일 샘플 정확도가 아님!

### 구체적 예시: "운 좋은" 문제

**문제 타입 A: "운 좋은 고온 문제"**

```
문제 특성:
- 모델이 이 문제에 대해 약간 불확실함
- 정답은 "42"
- 모델의 주된 추측: "40" (잘못됨)
- 하지만 약간의 랜덤성으로 "42"를 찾을 수 있음
```

**T=0.8에서 (높은 다양성):**
```
64개 샘플링:
  - 30개: "40" (틀림)
  - 25개: "41", "43", "38" 등 (틀림)
  - 9개: "42" (정답!) ✓

정확도: 9/64 = 14%... 아니 잠깐!

실제로는 여러 시드에서 측정:
  - seed 0: 9/64 = 14%
  - seed 42: 15/64 = 23%
  - seed 64: 12/64 = 19%

평균: (14 + 23 + 19) / 3 = 18.7%

아니다, 이건 L5가 될 것 같은데...
```

잠깐, 제 계산이 틀렸네요. 실제 데이터를 다시 보겠습니다.

실제로는 **집계 방법** 때문입니다!

### 진짜 이유: 다양성이 집계에 도움됨

**더 정확한 예시:**

문제: "2x + 5 = 13, x는?"

**모델의 능력:**
- T=0.1: 항상 같은 추론 경로 → 체계적 오류 가능
- T=0.8: 다양한 추론 경로 → 일부는 정답 발견

**T=0.1에서 (낮은 다양성):**
```
64개 샘플, 모두 비슷한 접근:
  Step 1: 2x = 13 - 5
  Step 2: 2x = 18  ← 체계적 오류 (8로 착각)
  Step 3: x = 9

64개 중 64개 모두 같은 실수 반복
정확도: 0/64 = 0%

여러 시드에서:
  seed 0: 일부 맞음 2/64 = 3%
  seed 42: 5/64 = 8%
  seed 64: 0/64 = 0%

평균: 3.7%
```

**T=0.8에서 (높은 다양성):**
```
64개 샘플, 다양한 접근:
  30개: 위와 같은 실수 → x = 9 (틀림)
  15개: 다른 방법 시도 → x = 7 (틀림)
  12개: 또 다른 방법 → x = 4 (정답!) ✓
  7개: 완전히 다른 접근 → x = 4 (정답!) ✓

정확도: 19/64 = 30%

여러 시드에서:
  seed 0: 25/64 = 39%
  seed 42: 20/64 = 31%
  seed 64: 15/64 = 23%

평균: 31%
```

**결과:**
- **T=0.8 기준선: 31% → L4 (20-40%)**
- **T=0.1 기준선: 3.7% → L5 (0-20%)**

**반대!** 😱

## 실제 데이터 패턴 분석

### BoN 분포 변화 재해석

```
ref0.1 → ref0.8 변화:

Level 1: 225 → 198 (-27)
  해석: T=0.1에서 "항상 맞는" 문제들 중 일부가
        T=0.8에서는 노이즈 때문에 정확도 떨어짐

Level 2: 27 → 42 (+15)
  해석: T=0.1에서 L1이던 27개 중 일부가 여기로 이동
        그리고 T=0.8의 다양성으로 새로 들어온 문제들

Level 3: 23 → 28 (+5)
Level 4: 33 → 50 (+17)
Level 5: 192 → 182 (-10)
  해석: T=0.8의 다양성이 일부 어려운 문제를 풀게 함!
```

### 핵심 통찰

**두 가지 상반된 효과:**

1. **노이즈 효과 (부정적):**
   - T=0.8은 랜덤 → 쉬운 문제도 실수 가능
   - L1 문제 일부가 L2로 하락

2. **다양성 효과 (긍정적):**
   - T=0.8은 다양한 시도 → 어려운 문제 일부 해결
   - L5/L4 문제 일부가 L2/L3로 상승

**순 효과:**
- 매우 쉬운 문제 (L1): 노이즈 효과 > 다양성 효과 → 개수 감소
- 중간 문제 (L2-L4): 다양성 효과 > 노이즈 효과 → 개수 증가
- 매우 어려운 문제 (L5): 다양성 효과 약간 → 개수 감소

## 당신의 직관이 맞는 경우

### "순수하게 쉬운" 문제

```
문제: "1 + 1 = ?"

T=0.1: 100% (당연히 맞음)
T=0.8: 98% (거의 항상 맞지만 가끔 이상한 답)

ref0.1: L1 ✓
ref0.8: L1 ✓

→ 이런 문제는 당신의 직관대로 작동합니다!
```

### "경계선" 문제

```
문제: 적당히 어려운 대수 문제

T=0.1: 75% (체계적 접근, 일부는 틀린 방법)
T=0.8: 85% (다양한 시도, 우연히 맞는 경우 많음)

ref0.1: L2 (60-80%)
ref0.8: L1 (80-100%)

→ T=0.8에서 L1인데 T=0.1에서 L2!
```

**당신이 질문한 것이 바로 이 두 번째 케이스입니다.**

## 왜 L1, L2에서 이런 일이?

### 당신의 직관: "L1, L2는 쉬운 거 아닌가?"

**맞습니다만, "쉬움"의 정의가 기준선에 의존합니다:**

**ref0.8 기준 L1 (198개):**
- "T=0.8의 노이즈에도 불구하고 80% 이상 맞는" 문제들
- 이 중 일부는 실제로:
  - T=0.8의 **다양성 덕분에** 80% 달성
  - T=0.1에서는 다양성 부족으로 75% (→ L2)

**ref0.1 기준 L1 (225개):**
- "T=0.1의 집중된 샘플로 80% 이상 맞는" 문제들
- 이 중 일부는:
  - T=0.8에서 노이즈 때문에 75% (→ L2)

### 실제 예시 추정

**ref0.8 L1 198개 문제의 구성 (추정):**
```
150개: "진짜 쉬운" 문제
  - T=0.1에서도 L1
  - T=0.8에서도 L1
  - 예: "1+1=?", "x+3=5, x=?"

48개: "다양성 덕분에 L1" 문제
  - T=0.8에서 L1 (다양한 시도로 85% 정확도)
  - T=0.1에서 L2 (체계적 오류로 70% 정확도)
  - 예: 복잡한 대수, 모델이 여러 접근법 중 하나가 맞음
```

**ref0.1 L1 225개 문제의 구성 (추정):**
```
150개: "진짜 쉬운" 문제 (위와 동일)

75개: "집중이 도움되는" 문제
  - T=0.1에서 L1 (체계적 접근으로 90% 정확도)
  - T=0.8에서 L2 (노이즈로 72% 정확도)
  - 예: 단계적 추론, 일관성이 중요한 문제
```

## DVTS에서 더 극단적

### DVTS의 Level 2 (ref0.8 기준)

```
ref0.8 L2: 54개 문제
최적 온도: T=0.8 (0.944 정확도)

왜 T=0.8이 최적?
→ 이 54개는 "다양성이 필요한" 문제들
→ T=0.8 기준선으로 필터링되어 선택됨
→ 당연히 T=0.8이 최적!
```

**자기 강화 효과:**
1. T=0.8 기준선 사용
2. "T=0.8에서 잘 푸는" 문제들이 L2로 분류됨
3. 이 문제들은 당연히 T=0.8에서 최적 성능
4. "T=0.8이 L2에 최적"이라는 결론

**이것은 순환 논리가 아닙니다:**
- 기준선 = 난이도 측정
- 최적 온도 = 성능 최대화
- 다른 개념이지만, 상관관계가 있음

## 결론: 당신의 직관 vs 현실

### 당신의 직관 (부분적으로 맞음)
```
"L1, L2는 쉬운 문제 → 어떤 온도든 잘 풀려야 함"
```

**맞는 부분:**
- 진짜 쉬운 문제 (예: 기초 산술)는 모든 온도에서 L1

**틀린 부분:**
- "쉬움"의 정의가 측정 방법에 의존
- T=0.8 L1 ≠ T=0.1 L1 (일부 문제)

### 현실 (복잡함)
```
"쉬움"은 절대적이지 않음
- 일부 문제는 다양성이 도움 (T=0.8에서 더 쉬움)
- 일부 문제는 집중이 도움 (T=0.1에서 더 쉬움)
```

### 핵심 교훈

**문제 난이도는 3가지에 의존:**
1. 문제 자체의 복잡도
2. 모델의 능력
3. **샘플링 전략 (온도!)**

**따라서:**
- ref0.8 L1 = "T=0.8 샘플링으로 쉬운" 문제
- ref0.1 L1 = "T=0.1 샘플링으로 쉬운" 문제
- 두 집합은 **다릅니다!**

## 실용적 시사점

### 어떤 기준선을 사용해야 하나?

**T=0.1 기준선 권장:**
```
이유:
1. 더 적은 노이즈 → 더 안정적 분류
2. "진짜 쉬운" 문제를 더 잘 식별
3. 일반적으로 더 직관적
```

**하지만:**
- 다양성이 중요한 도메인 → T=0.8도 고려
- 여러 기준선 테스트 → 민감도 확인

### 당신의 질문에 대한 최종 답변

**"왜 ref0.8 L1, L2가 ref0.1 L1, L2와 다른가?"**

**답변:**
1. **다양성 vs 집중** 트레이드오프
2. 일부 문제는 T=0.8의 **다양한 시도**로 더 잘 풀림
3. 일부 문제는 T=0.1의 **일관된 추론**으로 더 잘 풀림
4. "쉬움"은 샘플링 전략에 상대적임
5. 따라서 ref0.8 L1 ⊄ ref0.1 L1

**반직관적이지만 맞습니다!**

이것이 바로 이 분석이 흥미로운 이유입니다 - 온도가 단순히 "노이즈"가 아니라 **탐색 전략**임을 보여줍니다.
